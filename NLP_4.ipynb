{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount Google Drive and check for available GPU\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU detected:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU available; using CPU.\")\n",
        "\n",
        "# 2) Install required libraries\n",
        "!pip install nltk tqdm bs4\n",
        "\n",
        "# 3) Import libraries\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# 4) Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# 5) Load the IMDB dataset\n",
        "csv_path = '/content/drive/MyDrive/IMDB_Dataset.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Dataset shape (rows × columns):\", df.shape)\n",
        "print(\"Sentiment distribution:\\n\", df['sentiment'].value_counts())\n",
        "df.head()\n",
        "\n",
        "# 6) Define text preprocessing function\n",
        "stemmer = SnowballStemmer('english')\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    1. Remove HTML tags\n",
        "    2. Remove non-alphabet characters and convert to lowercase\n",
        "    3. Tokenize into words\n",
        "    4. Remove stopwords and apply stemming\n",
        "    5. Rejoin tokens into a single string\n",
        "    \"\"\"\n",
        "    # 1) Strip HTML\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "    # 2) Remove non-letters & lowercase\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text).lower()\n",
        "    # 3) Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # 4) Remove stopwords and stem\n",
        "    tokens = [stemmer.stem(tok) for tok in tokens if tok not in stops and len(tok) > 1]\n",
        "    # 5) Join tokens back into a string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# 7) Apply preprocessing to all reviews\n",
        "tqdm.pandas()\n",
        "df['cleaned'] = df['review'].progress_map(preprocess_text)\n",
        "df[['review','cleaned']].head()\n",
        "\n",
        "# 8) Feature extraction\n",
        "# a) Bag-of-Words\n",
        "cv = CountVectorizer(max_features=10000)\n",
        "X_bow = cv.fit_transform(df['cleaned'])\n",
        "# b) TF–IDF (optional)\n",
        "tfidf = TfidfVectorizer(max_features=10000)\n",
        "X_tfidf = tfidf.fit_transform(df['cleaned'])\n",
        "\n",
        "# 9) Encode target labels\n",
        "y = df['sentiment'].map({'positive': 1, 'negative': 0}).values\n",
        "\n",
        "# 10) Split into training and test sets (using BoW features)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_bow, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 11) Train & evaluate Gaussian Naive Bayes on BoW\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train.toarray(), y_train)\n",
        "y_pred_gnb = gnb.predict(X_test.toarray())\n",
        "\n",
        "print(\"\\n=== Gaussian Naive Bayes (BoW) Results ===\")\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_gnb))\n",
        "print(\"ROC AUC:  \", roc_auc_score(y_test, y_pred_gnb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gnb))\n",
        "print(classification_report(y_test, y_pred_gnb, target_names=['negative', 'positive']))\n",
        "\n",
        "# 12) Train & evaluate Random Forest on BoW\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Random Forest (BoW) Results ===\")\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"ROC AUC:  \", roc_auc_score(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['negative', 'positive']))\n",
        "\n",
        "# 13) Repeat training & evaluation using TF–IDF features\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
        "    X_tfidf, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- Gaussian Naive Bayes on TF–IDF ---\n",
        "gnb_tfidf = GaussianNB()\n",
        "gnb_tfidf.fit(X_train_tfidf.toarray(), y_train_tfidf)\n",
        "y_pred_gnb_tfidf = gnb_tfidf.predict(X_test_tfidf.toarray())\n",
        "\n",
        "print(\"\\n=== Gaussian Naive Bayes (TF–IDF) Results ===\")\n",
        "print(\"Accuracy: \", accuracy_score(y_test_tfidf, y_pred_gnb_tfidf))\n",
        "print(\"ROC AUC:  \", roc_auc_score(y_test_tfidf, y_pred_gnb_tfidf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_tfidf, y_pred_gnb_tfidf))\n",
        "print(classification_report(y_test_tfidf, y_pred_gnb_tfidf, target_names=['negative', 'positive']))\n",
        "\n",
        "# --- Random Forest on TF–IDF ---\n",
        "rf_tfidf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
        "y_pred_rf_tfidf = rf_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\n=== Random Forest (TF–IDF) Results ===\")\n",
        "print(\"Accuracy: \", accuracy_score(y_test_tfidf, y_pred_rf_tfidf))\n",
        "print(\"ROC AUC:  \", roc_auc_score(y_test_tfidf, y_pred_rf_tfidf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_tfidf, y_pred_rf_tfidf))\n",
        "print(classification_report(y_test_tfidf, y_pred_rf_tfidf, target_names=['negative', 'positive']))\n",
        "\n",
        "# 14) Interactive prediction example\n",
        "user_review = input(\"Please enter a movie review: \")\n",
        "cleaned_review = preprocess_text(user_review)\n",
        "vectorized_review = cv.transform([cleaned_review])\n",
        "prediction = rf.predict(vectorized_review)[0]\n",
        "print(\"Predicted sentiment:\", 'positive' if prediction == 1 else 'negative')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLcVMbJx946Z",
        "outputId": "267d93af-8ee5-4ef9-bd8a-1e876fe5637f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Running on device: cpu\n",
            "No GPU available; using CPU.\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.14.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape (rows × columns): (50000, 2)\n",
            "Sentiment distribution:\n",
            " sentiment\n",
            "positive    25000\n",
            "negative    25000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:26<00:00, 342.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Gaussian Naive Bayes (BoW) Results ===\n",
            "Accuracy:  0.6882\n",
            "ROC AUC:   0.6895336312261238\n",
            "Confusion Matrix:\n",
            " [[4269  692]\n",
            " [2426 2613]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.64      0.86      0.73      4961\n",
            "    positive       0.79      0.52      0.63      5039\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.71      0.69      0.68     10000\n",
            "weighted avg       0.71      0.69      0.68     10000\n",
            "\n",
            "\n",
            "=== Random Forest (BoW) Results ===\n",
            "Accuracy:  0.8464\n",
            "ROC AUC:   0.8464093755464082\n",
            "Confusion Matrix:\n",
            " [[4205  756]\n",
            " [ 780 4259]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.85      0.85      4961\n",
            "    positive       0.85      0.85      0.85      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "=== Gaussian Naive Bayes (TF–IDF) Results ===\n",
            "Accuracy:  0.7578\n",
            "ROC AUC:   0.7582673329845387\n",
            "Confusion Matrix:\n",
            " [[4059  902]\n",
            " [1520 3519]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.82      0.77      4961\n",
            "    positive       0.80      0.70      0.74      5039\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.76     10000\n",
            "weighted avg       0.76      0.76      0.76     10000\n",
            "\n",
            "\n",
            "=== Random Forest (TF–IDF) Results ===\n",
            "Accuracy:  0.8517\n",
            "ROC AUC:   0.8517635212926354\n",
            "Confusion Matrix:\n",
            " [[4266  695]\n",
            " [ 788 4251]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.86      0.85      4961\n",
            "    positive       0.86      0.84      0.85      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}